Arguments are...
log_dir: ./qm9_conf_1_60
data_dir: data/QM9/qm9/
split_path: data/QM9/splits/split0.npy
trained_local_model: None
restart_dir: None
dataset: qm9
seed: 0
n_epochs: 60
warmup_epochs: 2
batch_size: 16
lr: 0.001
num_workers: 0
optimizer: adam
scheduler: plateau
verbose: False
model_dim: 25
random_vec_dim: 10
random_vec_std: 1
random_alpha: False
n_true_confs: 1
n_model_confs: 1
gnn1_depth: 3
gnn1_n_layers: 2
gnn2_depth: 3
gnn2_n_layers: 2
encoder_n_head: 2
coord_pred_n_layers: 2
d_mlp_n_layers: 1
h_mol_mlp_n_layers: 1
alpha_mlp_n_layers: 2
c_mlp_n_layers: 1
global_transformer: False
loss_type: ot_emd
teacher_force: False
separate_opts: False

Model parameters are:
hyperparams:
  model_dim: 25
  random_vec_dim: 10
  random_vec_std: 1
  global_transformer: False
  n_true_confs: 1
  n_model_confs: 1
  gnn1:
    depth: 3
    n_layers: 2
  gnn2:
    depth: 3
    n_layers: 2
  encoder:
    n_head: 2
  coord_pred:
    n_layers: 2
  d_mlp:
    n_layers: 1
  h_mol_mlp:
    n_layers: 1
  alpha_mlp:
    n_layers: 2
  c_mlp:
    n_layers: 1
  loss_type: ot_emd
  teacher_force: False
  random_alpha: False
num_node_features: 44
num_edge_features: 4


Starting training...
Epoch 1: Training Loss -0.6157184416145086
Epoch 1: Validation Loss -0.2833246845929396
Epoch 2: Training Loss -0.9909265325427056
Epoch 2: Validation Loss -1.1274577644136217
Epoch 3: Training Loss -1.1766451460838319
Epoch 3: Validation Loss -1.1957451843080067
Epoch 4: Training Loss -1.2374868898391724
Epoch 4: Validation Loss -1.246903415710207
Epoch 5: Training Loss -1.2553733108520508
Epoch 5: Validation Loss -1.1838887381175207
Epoch 6: Training Loss -1.2819547174453736
Epoch 6: Validation Loss -1.2630813878680032
Epoch 7: Training Loss -1.308647025680542
Epoch 7: Validation Loss -1.3547527222406297
Epoch 8: Training Loss -1.352048808479309
Epoch 8: Validation Loss -1.3551282598858787
Epoch 9: Training Loss -1.376355173110962
Epoch 9: Validation Loss -1.4100934229199849
Epoch 10: Training Loss -1.394251988220215
Epoch 10: Validation Loss -1.4210665528736417
Epoch 11: Training Loss -1.4046830179214478
Epoch 11: Validation Loss -1.3922159331185477
Epoch 12: Training Loss -1.410108780670166
Epoch 12: Validation Loss -1.3671416498365856
Epoch 13: Training Loss -1.4150786055564881
Epoch 13: Validation Loss -1.3865724045132835
Epoch 14: Training Loss -1.424121422767639
Epoch 14: Validation Loss -1.3937791491311693
Epoch 15: Training Loss -1.4150113092422485
Epoch 15: Validation Loss -1.415501113921877
Epoch 16: Training Loss -1.4367735311508179
Epoch 16: Validation Loss -1.4554872474973164
Epoch 17: Training Loss -1.441315733909607
Epoch 17: Validation Loss -1.4661478523224118
Epoch 18: Training Loss -1.4541975442886352
Epoch 18: Validation Loss -1.4855169814730447
Epoch 19: Training Loss -1.4543458457946776
Epoch 19: Validation Loss -1.4431613645856343
Epoch 20: Training Loss -1.4553188077926635
Epoch 20: Validation Loss -1.4703284918315827
Epoch 21: Training Loss -1.448900617980957
Epoch 21: Validation Loss -1.4742565192873516
Epoch 22: Training Loss -1.4607527755737304
Epoch 22: Validation Loss -1.451949880236671
Epoch 23: Training Loss -1.44587225189209
Epoch 23: Validation Loss -1.4607169874130734
Epoch 24: Training Loss -1.464426037788391
Epoch 24: Validation Loss -1.4734783172607422
Epoch 25: Training Loss -1.490839965248108
Epoch 25: Validation Loss -1.5182523992326524
Epoch 26: Training Loss -1.501975196838379
Epoch 26: Validation Loss -1.5352906632044958
Epoch 27: Training Loss -1.5146212633132934
Epoch 27: Validation Loss -1.5294414607305375
Epoch 28: Training Loss -1.4935484845161437
Epoch 28: Validation Loss -1.461908251520187
Epoch 29: Training Loss -1.5179646921157837
Epoch 29: Validation Loss -1.5038862682524181
Epoch 30: Training Loss -1.5193508020401
Epoch 30: Validation Loss -1.507402115397983
Epoch 31: Training Loss -1.5268763463974
Epoch 31: Validation Loss -1.536505176907494
Epoch 32: Training Loss -1.4918383419036865
Epoch 32: Validation Loss -1.4689651387078422
Epoch 33: Training Loss -1.5295137222290038
Epoch 33: Validation Loss -1.5378495341255551
Epoch 34: Training Loss -1.5343598957061768
Epoch 34: Validation Loss -1.5254841021129064
Epoch 35: Training Loss -1.5338667545318603
Epoch 35: Validation Loss -1.5425347941262382
Epoch 36: Training Loss -1.5376613368988037
Epoch 36: Validation Loss -1.557618706945389
Epoch 37: Training Loss -1.5393700710296632
Epoch 37: Validation Loss -1.5467758822062658
Epoch 38: Training Loss -1.5204521453857422
Epoch 38: Validation Loss -1.5589838160408869
Epoch 39: Training Loss -1.5375957693099975
Epoch 39: Validation Loss -1.5484017947363475
Epoch 40: Training Loss -1.545221663093567
Epoch 40: Validation Loss -1.5574112506139846
Epoch 41: Training Loss -1.5500653800964355
Epoch 41: Validation Loss -1.5443146853219896
Epoch 42: Training Loss -1.5427599407196044
Epoch 42: Validation Loss -1.5632968535498968
Epoch 43: Training Loss -1.5375324966430663
Epoch 43: Validation Loss -1.5368232727050781
Epoch 44: Training Loss -1.5053795082092285
Epoch 44: Validation Loss -1.5084927592958723
Epoch 45: Training Loss -1.5367076389312744
Epoch 45: Validation Loss -1.5557055075963337
Epoch 46: Training Loss -1.5470589323043824
Epoch 46: Validation Loss -1.479418811343965
Epoch 47: Training Loss -1.5082454956054687
Epoch 47: Validation Loss -1.5211681619523063
Epoch 48: Training Loss -1.5456981910705567
Epoch 48: Validation Loss -1.5440123156895713
Epoch 49: Training Loss -1.5621672647476197
Epoch 49: Validation Loss -1.5630756654436626
Epoch 50: Training Loss -1.5693295532226563
Epoch 50: Validation Loss -1.5805022167781042
Epoch 51: Training Loss -1.5717633716583252
Epoch 51: Validation Loss -1.5459319485558405
Epoch 52: Training Loss -1.5748785577774047
Epoch 52: Validation Loss -1.5736132841261605
Epoch 53: Training Loss -1.5774588827133178
Epoch 53: Validation Loss -1.5835847022041443
Epoch 54: Training Loss -1.5764026008605958
Epoch 54: Validation Loss -1.577660009974525
Epoch 55: Training Loss -1.5746269563674926
Epoch 55: Validation Loss -1.5959871950603666
Epoch 56: Training Loss -1.5741423986434937
Epoch 56: Validation Loss -1.5804614831530859
Epoch 57: Training Loss -1.578863064956665
Epoch 57: Validation Loss -1.5966124061554197
Epoch 58: Training Loss -1.5689758462905883
Epoch 58: Validation Loss -1.5943453368686495
Epoch 59: Training Loss -1.5694687576293946
Epoch 59: Validation Loss -1.5816081724469624
Best Validation Loss -1.5966124061554197 on Epoch 57
